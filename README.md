# Сервис поиска похожих вопросов для медицинских форумов

## Описание

### Цель

Целью данного проекта является разработка сервиса для поиска похожих вопросов на медицинских форумах. Сервис поможет удержать пользователей на платформе и увеличить количество просмотров страниц, что в свою очередь повысит эффективность рекламных кампаний и улучшит общие показатели форумов.

### Исходные данные

Для обучения и тестирования моделей используется датасет "medical_questions_pairs" от Hugging Face.  Датасет содержит пары вопросов на английском языке, связанных с медицинской тематикой.

### Методы

В проекте будут использованы следующие методы и технологии:

* Обработка естественного языка (NLP) для анализа и предобработки текстовых данных.
* Машинное обучение с использованием различных моделей NLP, таких как Bag-of-Words, TF-IDF, Word2Vec, SentenceTransformers и USE. 
* FastAPI для создания микросервиса, предоставляющего функциональность поиска похожих вопросов.
* Streamlit для разработки интерактивного веб-приложения для демонстрации работы сервиса.

### Метрики оценки

Качество матчинга вопросов будет оцениваться с использованием следующих метрик: 

* Accuracy@5 - `ключевая метрика`
* MRR@K (Mean Reciprocal Rank)
* DCG@K (Discounted Cumulative Gain)
* AccuracyTriplet - доля правильно классифицированных триплетов

## Итоги

**Наблюдения:**
* **Все модели SentenceTransformer показали более высокое качество по всем метрикам чем дергие модели, рассмотренные в этом проекте.** При этом скорость работы этих моделей значительно ниже, но так как для данной задачи скорость работы всё равно остаётся в пределах нормы, то выбор лучшей модели будет осуществляться среди моделей SentenceTransformer.
* ***Модель all-mpnet-base-v2 показала наилучшую точность (Accuracy@5) как на исходных, так и на предобработанных данных. Точность на исходных данных - 96.82%*** Это говорит о том, что эта модель хорошо подходит для нашей задачи поиска похожих вопросов.
* ***Предобработка текста не привела к улучшению точности.*** В большинстве случаях, точность даже немного снизилась. Это может быть связано с тем, что предобработка удаляет некоторую информацию, которая может быть полезна для модели.
* ***Модели среднего размера (all-MiniLM-L6-v2, all-MiniLM-L12-v2) также показали хорошую точность. Они могут быть хорошим выбором, если важна скорость работы.***
* *Модели, специально обученные для задач Question Answering (multi-qa-MiniLM-L6-cos-v1, multi-qa-distilbert-cos-v1, multi-qa-mpnet-base-dot-v1), показали немного худшую точность, чем all-mpnet-base-v2, all-MiniLM-L6-v2 и all-MiniLM-L12-v2.*
* Метрики `MMR@5`и`DCG@5` на уровене 90%+ (0.9+) указывают на то что в большинстве случаев модель ранжирует правильный вопрос на первое место и реже на второе и ниже.

**Выбор модели:**
- Для дальнейшей разработки я буду использовать модель **`all-MiniLM-L6-v2`**, которая показала почти такой же результат (точность 96.36%) что и `all-mpnet-base-v2`, но при этом работает почти в 6 раз быстрее.

## Модель

**Выбрана модель из библиотеки SentenceTransformers - *all-MiniLM-L6-v2*, метрики модели:**
- Accuracy@5: 96.36%
- MRR@5: 90.39%
- DCG@5: 90.94%
- AccuracyTriplet: 94.82%

## Cтатус:
Финализация проекта:
- Составление отчёта